{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22344,
     "status": "ok",
     "timestamp": 1697690195158,
     "user": {
      "displayName": "Steven",
      "userId": "10893707739290145739"
     },
     "user_tz": -480
    },
    "id": "kBiYZ6b3DEfZ",
    "outputId": "1f860014-d53e-44b5-ea9d-6695a8801941"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27976\\3631586751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "from segmentation_models_pytorch import Unet\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {0: 'Basophil', 1: 'Eosinophil', 2: 'Lymphocyte', 3: 'Monocyte', 4: 'Neutrophil'}\n",
    "label_to_id = {'Basophil': 0, 'Eosinophil': 1, 'Lymphocyte': 2, 'Monocyte': 3, 'Neutrophil': 4}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "\n",
    "        for subdir in os.listdir(root_dir):\n",
    "            if os.path.isdir(os.path.join(root_dir, subdir)):\n",
    "                for filename in os.listdir(os.path.join(root_dir, subdir)):\n",
    "                    if filename.endswith(\".jpg\"):\n",
    "                        self.images.append(os.path.join(root_dir, subdir, filename))\n",
    "                        self.targets.append(label_to_id[subdir])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = label_to_id[os.path.basename(os.path.dirname(image_path))]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRJDEBpPDY6p"
   },
   "outputs": [],
   "source": [
    "def init(porportion, resize):    \n",
    "    WBC_1_train_dir = 'WBC_1/train/data'\n",
    "    WBC_1_train_mask_dir = 'WBC_1/train/mask'\n",
    "    WBC_1_train_pred_mask_dir = 'WBC_1/train/pred_mask'\n",
    "    WBC_10_train_dir = 'WBC_10/train/data'\n",
    "    WBC_10_train_mask_dir = 'WBC_10/train/mask'\n",
    "    WBC_10_train_pred_mask_dir = 'WBC_10/train/pred_mask'\n",
    "    WBC_50_train_dir = 'WBC_50/train/data'\n",
    "    WBC_50_train_mask_dir = 'WBC_50/train/mask'\n",
    "    WBC_50_train_pred_mask_dir = 'WBC_50/train/pred_mask'\n",
    "    WBC_100_train_dir = 'WBC_100/train/data'\n",
    "    WBC_100_train_mask_dir = 'WBC_100/train/mask'\n",
    "    WBC_100_train_pred_mask_dir = 'WBC_100/train/pred_mask'\n",
    "    WBC_100_val_dir = 'WBC_100/val/data'\n",
    "    WBC_100_mask_dir = 'WBC_100/val/mask'\n",
    "    CAM16_100_train_dir = 'CAM16_100cls_10mask/train/data'\n",
    "    CAM16_100_train_mask_dir = 'CAM16_100cls_10mask/train/mask'\n",
    "    CAM16_100_val_dir = 'CAM16_100cls_10mask/val/data'\n",
    "    CAM16_100_test_dir = 'CAM16_100cls_10mask/test/data'\n",
    "\n",
    "\n",
    "    WBC_train_dir = 'WBC_' + str(proportion) + '/train/data'\n",
    "    WBC_mask_dir = 'WBC_' + str(proportion) + '/train/mask'\n",
    "    WBC_pred_mask_dir ='WBC_' + str(proportion) + '/train/pred_mask'\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(resize),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((resize, resize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = CustomDataset(root_dir=WBC_train_dir, transform=train_transform)\n",
    "    val_dataset = CustomDataset(root_dir=WBC_100_val_dir, transform=val_transform)\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # if device == torch.device(\"cuda\"):\n",
    "    #     train_dataset = [(x.to(device), torch.tensor([y]).to(device)) for x, y in train_dataset]\n",
    "    #     val_dataset = [(x.to(device), torch.tensor([y]).to(device)) for x, y in val_dataset]\n",
    "\n",
    "    batch_size = 32\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    train_label_counts = Counter(train_dataset.targets)\n",
    "    val_label_counts = Counter(val_dataset.targets)\n",
    "    \n",
    "    return train_dataloader, val_dataloader, train_label_counts, val_label_counts, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91536,
     "status": "ok",
     "timestamp": 1697691165287,
     "user": {
      "displayName": "Steven",
      "userId": "10893707739290145739"
     },
     "user_tz": -480
    },
    "id": "el4DHCPADacg",
    "outputId": "7b522e4b-6485-4406-8b31-1f95c30fe532",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, train_label_counts, val_label_counts,\n",
    "          classifier_model_load_path, classifier_model_save_path, \n",
    "          mask_model_load_path, device, alpha1, alpha2):\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.manual_seed(3407)\n",
    "    \n",
    "    val_acc = 0\n",
    "    class_counts = []\n",
    "    \n",
    "    for label, count in train_label_counts.items():\n",
    "        class_counts.append(count)\n",
    "    class_weights = [1.0 / count for count in class_counts]\n",
    "    \n",
    "    classifier_model = models.resnet34(pretrained=True)\n",
    "    mask_model = Unet('resnet34', in_channels=3, classes=1).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights)).to(device)\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    lr = 0.02\n",
    "    epochs = int(700 / proportion)\n",
    "    \n",
    "    opt = optim.SGD(classifier_model.parameters(), lr=lr)\n",
    "    sch = optim.lr_scheduler.StepLR(opt, int(epochs / 7), 0.5)\n",
    "\n",
    "    if mask_model_load_path != \"\":\n",
    "        mask_model.load_state_dict(torch.load(mask_model_load_path))\n",
    "        \n",
    "    if classifier_model_load_path != \"\":\n",
    "        classifier_model.fc = nn.Linear(classifier_model.fc.in_features, 2)\n",
    "        classifier_model.load_state_dict(torch.load(classifier_model_load_path))\n",
    "    \n",
    "    classifier_model.fc = nn.Linear(classifier_model.fc.in_features, 5)\n",
    "    num_layers_to_freeze = 10\n",
    "    for i, param in enumerate(classifier_model.parameters()):\n",
    "        if i < num_layers_to_freeze:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        classifier_model = classifier_model.to(device)\n",
    "        mask_model = mask_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "    val_accuracies = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    mask_model.eval()\n",
    "    for epoch in range(epochs):\n",
    "        classifier_model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "        io_time = 0\n",
    "        train_time = 0\n",
    "        eval_time = 0\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            io_start_time = time.time()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            io_time += time.time() - io_start_time\n",
    "            pred = classifier_model(inputs)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_mask = mask_model(inputs)\n",
    "                pred_probability = torch.sigmoid(pred_mask)\n",
    "                mask = (pred_probability > 0.5)\n",
    "            masked_loss = criterion(pred, labels) * (mask.float() * alpha1 + alpha2)\n",
    "\n",
    "            loss = torch.sum(masked_loss) / torch.sum(mask.float())\n",
    "            \n",
    "#             loss = criterion(pred, labels)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        sch.step()\n",
    "        train_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_dataloader)}')\n",
    "        accuracy = 100 * correct / total\n",
    "        train_accuracies.append(accuracy)\n",
    "        print(f'Train Accuracy: {accuracy:.2f}%')\n",
    "        losses.append(running_loss / len(train_dataloader))\n",
    "\n",
    "        failed_images = []\n",
    "        failed_masks = []\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        \n",
    "        error_label_counts = [0 for _ in range(len(val_label_counts))]\n",
    "        \n",
    "        mod = max(int(epochs/10), 1)\n",
    "        if epoch % mod == mod - 1 or epoch % mod == 0:\n",
    "            classifier_model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_dataloader:\n",
    "                    io_start_time = time.time()\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    io_time += time.time() - io_start_time\n",
    "                    pred = classifier_model(inputs)\n",
    "                    _, predicted = torch.max(pred, 1)\n",
    "                    total += len(labels)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    for i in range(len(labels)):\n",
    "                        if predicted[i] != labels[i]:\n",
    "                            predicted_labels.append(predicted[i].item())\n",
    "                            true_labels.append(labels[i].item())\n",
    "                            error_label_counts[labels[i]] += 1\n",
    "                            \n",
    "#                             if epoch == epochs - 1:\n",
    "#                                 pred_mask = mask_model(inputs[i].unsqueeze(0))\n",
    "#                                 pred_probability = torch.sigmoid(pred_mask.squeeze(0).squeeze(0))\n",
    "#                                 mask = (pred_probability > 0.5)\n",
    "#                                 failed_masks.append(mask.cpu().numpy())\n",
    "#                                 failed_images.append(inputs[i].cpu().numpy())\n",
    "                \n",
    "#                 for i in range(len(error_label_counts)):\n",
    "#                     print(id_to_label[i], 'Error Rate: {:.2%}'.format(error_label_counts[i] / val_label_counts[i]))\n",
    "                \n",
    "#                 if epoch == epochs - 1:\n",
    "#                     for i in range(len(failed_images)):\n",
    "#                         fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 16))\n",
    "#                         ax1.figure.set_size_inches(6, 6)\n",
    "#                         ax1.imshow(np.transpose(failed_images[i], (1, 2, 0)))\n",
    "#                         ax1.set_title(f\"Pred: {id_to_label[predicted_labels[i]]}, True: {id_to_label[true_labels[i]]}\")\n",
    "#                         ax1.axis('off')\n",
    "\n",
    "#                         ax2.figure.set_size_inches(6, 6)\n",
    "#                         ax2.imshow(failed_masks[i], cmap='gray')\n",
    "#                         ax2.set_title(\"Predicted Mask\")\n",
    "#                         ax2.axis('off')\n",
    "\n",
    "#                         plt.show()\n",
    "\n",
    "            eval_time = time.time() - start_time\n",
    "            accuracy = 100 * correct / total\n",
    "            val_acc = max(val_acc, accuracy)\n",
    "            print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "            val_accuracies.append(accuracy)\n",
    "        else:\n",
    "            val_accuracies.append(val_accuracies[-1])\n",
    "            \n",
    "        print('IO:', io_time, 'Train:', train_time, 'Eval:', eval_time)\n",
    "        \n",
    "    torch.save(classifier_model.state_dict(), classifier_model_save_path)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "    ax1.plot(range(epochs), losses, label='Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss Over Epochs')\n",
    "\n",
    "    ax2.plot(range(epochs), val_accuracies, label='Validation Accuracy')\n",
    "    ax2.plot(range(epochs), train_accuracies, label='Train Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Accuracy Over Epochs')\n",
    "    \n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = [1, 10, 50, 100]\n",
    "resize = 224\n",
    "alpha1s = [-1]\n",
    "alpha2s = [1]\n",
    "for proportion in proportions:\n",
    "    for alpha1, alpha2 in zip(alpha1s, alpha2s):\n",
    "        mask_model_load_path = \"CustomLoss_UNet_WBC\" + str(proportion) +\"_model.pth\"\n",
    "        classifier_model_load_path = \"\"\n",
    "        classifier_model_save_path = \"Pretrained_ResNet34_WBC\" + str(proportion) +\"_model.pth\"\n",
    "        train_dataloader, val_dataloader, train_label_counts, val_label_counts, device = init(proportion, resize)\n",
    "        val_acc = train(train_dataloader, val_dataloader, train_label_counts, val_label_counts, classifier_model_load_path, \n",
    "              classifier_model_save_path, mask_model_load_path, device, alpha1, alpha2)\n",
    "        print(proportion, alpha1, alpha2, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion = 100\n",
    "# resize = 224\n",
    "# alpha1 = -1\n",
    "# alpha2 = 1\n",
    "# mask_model_load_path = \"CustomLoss_UNet_WBC\" + str(proportion) +\"_model.pth\"\n",
    "# classifier_model_load_path = \"\"\n",
    "# classifier_model_save_path = \"Pretrained_ResNet34_WBC\" + str(proportion) +\"_model.pth\"\n",
    "# train_dataloader, val_dataloader, train_label_counts, val_label_counts, device = init(proportion, resize)\n",
    "# train(train_dataloader, val_dataloader, train_label_counts, val_label_counts, classifier_model_load_path, \n",
    "#       classifier_model_save_path, mask_model_load_path, device, alpha1, alpha2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([0, 10.32, 4.61, 8.42, 2.36]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPSxnuBKycS8Fff3BNmY1Wk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
